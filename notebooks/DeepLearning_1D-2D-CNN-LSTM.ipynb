{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ddf54f",
   "metadata": {},
   "source": [
    "Based on https://github.com/Hbbbbbby/EmotionRecognition_2Dcnn-lstm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c79e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import librosa\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.utils import normalize, to_categorical\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# import own functions\n",
    "from ipynb.fs.full.Functions import load_train_test_data, model_eval, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e76732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/emodb/wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea73d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_mel_spectrogram(path, n_fft=2048, hop_length=512, sample_rate=16000, duration=8, n_mels=128):\n",
    "    \"\"\"\n",
    "    Extract log mel spectrogram with given duration and sample rate.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(path, sr=sample_rate, duration=duration)\n",
    "\n",
    "    file_length = np.size(y)\n",
    "    \n",
    "    # pad shorter files & segment longer files than sample rate times duration to ensure same file length\n",
    "    if file_length < sr * duration: \n",
    "        y = np.concatenate((y, np.zeros(sr * duration - file_length)), axis=0)\n",
    "        \n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    log_mel_spectrogram = librosa.amplitude_to_db(mel_spectrogram)\n",
    "    log_mel_spectrogram = log_mel_spectrogram.reshape((-1,))\n",
    "\n",
    "    return log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6faa7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, train_test_val='ours'):\n",
    "    \"\"\"\n",
    "    Loads all log mel spectrograms and labels for files in the path.\n",
    "    returns: Dataframe with file name, log mel spectrogram, label.\n",
    "    \"\"\"\n",
    "    audio_files = os.listdir(path)\n",
    "    file_dict = {}\n",
    "    emotion_dict = {'W':'anger', 'L':'boredom', 'E':'disgust', 'A':'fear', 'F':'happiness', 'N':'neutral', 'T':'sadness'}\n",
    "    file_dict['file'] = []\n",
    "    file_dict['log_mel_spec'] = []\n",
    "    file_dict['label'] = []\n",
    "    for file in audio_files:\n",
    "        file_dict['file'].append(file)\n",
    "        file_dict['log_mel_spec'].append(get_log_mel_spectrogram(path + '/' + file))\n",
    "        file_dict['label'].append(emotion_dict[file[5]])\n",
    "    df = pd.DataFrame.from_dict(file_dict)\n",
    "    label_enc = preprocessing.LabelEncoder()\n",
    "    df['label'] = label_enc.fit_transform(df['label'])\n",
    "    \n",
    "    # load train, test, and validation data\n",
    "    if train_test_val == 'paper':\n",
    "        # load the train/test data \n",
    "        X_train, X_test, y_train, y_test = load_train_test_data(df, test_size = 0.2, verbose=False)\n",
    "\n",
    "        # split train set into validation and train data (this is not completely clear in the paper, follows github repo)\n",
    "        df_train = pd.concat([X_train, y_train], axis = 1)\n",
    "        X_train, X_val, y_train, y_val = load_train_test_data(df_train, test_size=0.2, split_type='train/val', verbose=False)\n",
    "    \n",
    "    elif train_test_val == 'ours':\n",
    "        # load the train/test data \n",
    "        X_train, X_test, y_train, y_test = load_train_test_data(df, test_size = 0.3, verbose=False)\n",
    "\n",
    "        # split test set into validation and test data\n",
    "        df_test = pd.concat([X_test, y_test], axis = 1)\n",
    "        X_val, X_test, y_val, y_test = load_train_test_data(df_test, test_size=0.5, split_type='val/test')\n",
    "    \n",
    "    print(\"There are {} entries in the training data.\".format(X_train.shape[0]))\n",
    "    print(\"There are {} entries in the testing data.\".format(X_test.shape[0]))\n",
    "    print(\"There are {} entries in the validation data.\".format(X_val.shape[0]))\n",
    "    \n",
    "    # reshape the data\n",
    "    X_train = np.concatenate([np.array(row) for row in X_train['log_mel_spec']]).reshape(-1, 128, 251, 1)\n",
    "    y_train = y_train.values\n",
    "    \n",
    "    X_test = np.concatenate([np.array(row) for row in X_test['log_mel_spec']]).reshape(-1, 128, 251, 1)\n",
    "    y_test = y_test.values\n",
    "    \n",
    "    X_val = np.concatenate([np.array(row) for row in X_val['log_mel_spec']]).reshape(-1, 128, 251, 1)\n",
    "    y_val = y_val.values\n",
    "        \n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f1dac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 342 entries in the training data.\n",
      "There are 107 entries in the testing data.\n",
      "There are 86 entries in the validation data.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = load_data(data_path, train_test_val='paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4dc99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
